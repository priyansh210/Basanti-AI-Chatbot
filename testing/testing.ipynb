{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21b7dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aswin\\AppData\\Local\\Temp\\ipykernel_20460\\1673708050.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_lg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdateparser\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygwalker\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpyg\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import dateparser\n",
    "import pygwalker as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4440e24f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_lg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb5b47ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashwin PERSON\n",
      "Rajesh PERSON\n",
      "[] []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>tag</th>\n",
       "      <th>children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>add</td>\n",
       "      <td>add</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>VB</td>\n",
       "      <td>[message, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>DT</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>message</td>\n",
       "      <td>message</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>NN</td>\n",
       "      <td>[a, for]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>IN</td>\n",
       "      <td>[Ashwin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ashwin</td>\n",
       "      <td>Ashwin</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>NNP</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>aux</td>\n",
       "      <td>TO</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>VERB</td>\n",
       "      <td>advcl</td>\n",
       "      <td>VB</td>\n",
       "      <td>[to, Rajesh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rajesh</td>\n",
       "      <td>Rajesh</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>NNP</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text    lemma    pos    dep  tag        children\n",
       "0      add      add   VERB   ROOT   VB  [message, see]\n",
       "1        a        a    DET    det   DT              []\n",
       "2  message  message   NOUN   dobj   NN        [a, for]\n",
       "3      for      for    ADP   prep   IN        [Ashwin]\n",
       "4   Ashwin   Ashwin  PROPN   pobj  NNP              []\n",
       "5       to       to   PART    aux   TO              []\n",
       "6      see      see   VERB  advcl   VB    [to, Rajesh]\n",
       "7   Rajesh   Rajesh  PROPN   dobj  NNP              []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#sentence = \"send a reminder for the meeting at 5 pm to everyone now and create a document for meeting notes then send a message to Rajesh sir.\"\n",
    "#sentence = \"send me a reminder on mail regarding the meeting tomorrow\"\n",
    "sentence = \"priyansh\"\n",
    "doc = nlp(sentence)\n",
    "graph = {}\n",
    "\n",
    "\n",
    "def generateTable(doc):\n",
    "\n",
    "    token_text = []\n",
    "    token_lemma = []\n",
    "    token_pos = []\n",
    "    token_tag = []\n",
    "    token_dep = []\n",
    "    token_children =[]\n",
    "    times = []\n",
    "    dates = []\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #get root_node \n",
    "    \n",
    "    for token in doc:\n",
    "        token_text.append(token.text)\n",
    "        token_lemma.append(token.lemma_ )\n",
    "        token_pos.append(token.pos_) \n",
    "        token_tag.append(token.tag_)\n",
    "        token_dep.append(token.dep_)\n",
    "        token_children.append([child.lemma_ for child in token.children])\n",
    "        graph[token] = token.children\n",
    "        if token.dep_==\"ROOT\":\n",
    "            root_node = token\n",
    "\n",
    "    df_dict = {\n",
    "        \"text\":token_text,\n",
    "        \"lemma\":token_lemma,\n",
    "        \"pos\":token_pos,\n",
    "        \"dep\":token_dep,\n",
    "        \"tag\":token_tag,\n",
    "        \"children\":token_children\n",
    "    }   \n",
    "\n",
    "\n",
    "#     get date time\n",
    "    for ent in doc.ents:\n",
    "            print(ent,ent.label_)\n",
    "            if ent.label_ in [\"TIME\", \"DATE\"]:\n",
    "                if ent.label_ == \"TIME\":\n",
    "                    times.append(ent.text)\n",
    "                elif ent.label_ == \"DATE\":\n",
    "                    dates.append(ent.text)\n",
    "    print(dates,times)\n",
    "\n",
    "    df = pd.DataFrame(df_dict)\n",
    "\n",
    "    return df,root_node\n",
    "\n",
    "df , root_node = generateTable(doc)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52a91e",
   "metadata": {},
   "source": [
    "Find the action in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef98595",
   "metadata": {},
   "outputs": [],
   "source": [
    "functionality_space = {\n",
    "    \"add reminder\":\"ADD MESSAGE\",\n",
    "    \"add message\":\"ADD MESSAGE\",\n",
    "    \"tell\":\"ADD MESSAGE\",\n",
    "    \"send message\":\"SEND MESSAGE\",\n",
    "    \"drop message\":\"ADD MESSAGE\",\n",
    "    \"have message\":\"GET MESSAGE\",\n",
    "    \"remind\":\"ADD MESSAGE\",\n",
    "    \"leave message\":\"ADD MESSAGE\",\n",
    "    \"add\":\"ADD\",\n",
    "    \"create list\":\"CREATE LIST\",\n",
    "    \"add event\":\"ADD TO SCHEDULE\",\n",
    "    \"schedule event\":\"ADD TO SCHEDULE\",\n",
    "    \"add expense\":\"REMOVE FUND\",\n",
    "    \"add fund\":\"ADD FUND\",\n",
    "    \"remove fund\":\"REMOVE FUND\",\n",
    "    \"spend\":\"REMOVE FUND\"\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117cdb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_functionality(action):\n",
    "    best_ans = (0,0)\n",
    "\n",
    "    for act in functionality_space:\n",
    "        doc1 = nlp(act)\n",
    "        doc2 = nlp(action)\n",
    "        similarity = doc1.similarity(doc2)\n",
    "        # print(data, similarity)\n",
    "        if similarity > best_ans[0]:\n",
    "            best_ans = (similarity,functionality_space[act])\n",
    "\n",
    "    return best_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45b25af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b71a5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_person = [\n",
    "    \"I\",\n",
    "    \"everyone\",\n",
    "    \"mashaal\",\n",
    "    \"priyansh\",\n",
    "    \"anmol\",\n",
    "    \"divyansh\",\n",
    "    \"rupesh\",\n",
    "    \"rajesh\",\n",
    "    \"ashutosh\",\n",
    "    \"naveen\",\n",
    "    \"harshit\",\n",
    "    \"aswin\",\n",
    "    \"herchelle\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286ffed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_objects = [\n",
    "    \"messsage\",\n",
    "    \"schedule\",\n",
    "    \"inventory\",\n",
    "    \"funds\",\n",
    "    \"list\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701d31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def find_known_names(sentence, known_names):\n",
    "    found_names = []\n",
    "    for word in sentence.split():\n",
    "        closest_match = difflib.get_close_matches(word, known_names, n=1, cutoff=0.7)\n",
    "        if closest_match:\n",
    "            found_names.append((word, closest_match[0]))\n",
    "    return found_names\n",
    "\n",
    "# found_names = find_known_names(sentence, known_person)\n",
    "# print(found_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f5d0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified Sentence : add a message for Ashwin to meet Herschelle\n",
      "Functionlaity: (1.0, 'ADD MESSAGE')\n",
      "Action : add message\n",
      "Who : []\n",
      "What: a message for Ashwin to meet Herschelle\n",
      "When: None\n",
      "Where: None\n",
      "{'FUNCTION': (1.0, 'ADD MESSAGE'), 'ACTION': 'add message', 'WHO': [], 'WHAT': 'a message for Ashwin to meet Herschelle', 'WHEN': None, 'WHERE': None}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "\n",
    "\n",
    "def break_querry(sentence):\n",
    "    \n",
    "    \n",
    "    #return dict\n",
    "    \n",
    "    answer = {}\n",
    "    \n",
    "    #simplify the sentence and retrieve the root, action\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    simple_sentence = \"\"\n",
    "    action = \"\"\n",
    "    start = False\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.tag_ == \"VBP\":\n",
    "            continue\n",
    "\n",
    "        elif token.dep_==\"ROOT\":\n",
    "            root_node = token\n",
    "            start = True\n",
    "            action+=\" \"+token.lemma_\n",
    "\n",
    "            for t in token.children:\n",
    "\n",
    "                if t.pos_==\"NOUN\" and t.dep_!=\"punct\":\n",
    "                    action+=\" \"+t.lemma_\n",
    "                    got_action = True\n",
    "                    break\n",
    "        \n",
    "        if start:\n",
    "            simple_sentence+=\" \"+token.text\n",
    "\n",
    "\n",
    "    sentence = simple_sentence.strip()\n",
    "    action = action.strip()\n",
    "    \n",
    "    print(\"Simplified Sentence :\",sentence)\n",
    "    \n",
    "    function =  find_functionality(action)\n",
    "    if function[0]<0.6:\n",
    "        phrase_handling(action)\n",
    "        \n",
    "    print(\"Functionlaity:\",function)\n",
    "    answer[\"FUNCTION\"]=function\n",
    "    \n",
    "    print(\"Action :\",action)\n",
    "    answer[\"ACTION\"]=action\n",
    "    \n",
    "    #find the target\n",
    "    \n",
    "    stack = [root_node]\n",
    "    visited=[root_node]\n",
    "    target_people = []\n",
    "    while stack:\n",
    "        token = stack.pop()\n",
    "        \n",
    "        for i in token.children:\n",
    "            if i.pos_ not in [\"VERB\"] and i not in visited:\n",
    "                stack.append(i)\n",
    "                visited.append(i)\n",
    "                if i.pos_ in [\"PRON\",\"PROPN\"] :\n",
    "                    target_people.append(i.lemma_)\n",
    "                \n",
    "\n",
    "    print(\"Who :\",target_people)\n",
    "    answer[\"WHO\"]=target_people\n",
    "    \n",
    "    context = sentence\n",
    "    \n",
    "    \n",
    "    #get what\n",
    "    \n",
    "    scheduled_for = \" \".join(target_people)\n",
    "    q1 = \"What should I \"+action +\"for?\"\n",
    "    w1 = qa_model(question = q1, context = context)\n",
    "    print(\"What:\",w1['answer'])\n",
    "    answer[\"WHAT\"]=w1['answer']\n",
    "    \n",
    "    \n",
    "    #get when parsed from date time\n",
    "\n",
    "    dates = []\n",
    "    times = []\n",
    "    for ent in doc.ents:\n",
    "\n",
    "        if ent.label_ in [\"TIME\", \"DATE\"]:\n",
    "            if ent.label_ == \"TIME\":\n",
    "                times.append(ent.text)\n",
    "            elif ent.label_ == \"DATE\":\n",
    "                dates.append(ent.text)\n",
    "\n",
    "    date = \"\".join(dates)\n",
    "    time = \"\".join(times)\n",
    "    input_text = date + \" \" + time\n",
    "    parsed_datetime = dateparser.parse(input_text)\n",
    "    print(\"When:\",parsed_datetime)\n",
    "    answer[\"WHEN\"]=parsed_datetime\n",
    "\n",
    "    \n",
    "    #get where\n",
    "\n",
    "    q4 = \"Where should I \"+action \n",
    "    w4 = qa_model(question = q4, context = context)\n",
    "    if w4[\"score\"]>0.5:\n",
    "        w4 = w4['answer']\n",
    "    else:\n",
    "        w4 = None\n",
    "\n",
    "    print(\"Where:\",w4)\n",
    "    answer[\"WHERE\"]=w4\n",
    "    \n",
    "    return answer\n",
    "    \n",
    "ans = break_querry(sentence)\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
